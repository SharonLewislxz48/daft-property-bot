#!/usr/bin/env python3
"""
–†–ï–ê–õ–¨–ù–´–ô –ø–∞—Ä—Å–µ—Ä daft.ie - –¢–û–õ–¨–ö–û –Ω–∞—Å—Ç–æ—è—â–∏–µ –¥–∞–Ω–Ω—ã–µ
–£–±—Ä–∞–Ω—ã –≤—Å–µ —Ñ–∞–ª—å—à–∏–≤—ã–µ –∏ –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ
"""
import asyncio
import aiohttp
import json
import random
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
import logging
import re
from datetime import datetime

logger = logging.getLogger(__name__)

class RealDaftParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å daft.ie"""
    
    def __init__(self):
        self.base_url = "https://www.daft.ie"
        self.session = None
        self.logger = logging.getLogger(__name__)
        
    async def create_session(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        if self.session:
            await self.session.close()
            
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-IE,en;q=0.9,en-US;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache',
            'Sec-Ch-Ua': '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': '"Windows"',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1',
            'Referer': 'https://www.google.ie/'
        }
        
        self.session = aiohttp.ClientSession(
            headers=headers,
            timeout=aiohttp.ClientTimeout(total=30),
            trust_env=True
        )
        return self.session

    async def get_real_content(self, url: str) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –æ–±—Ö–æ–¥–æ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏"""
        methods = [
            self.try_direct_request,
            self.try_with_cookies,
            self.try_mobile_version,
            self.try_cached_version
        ]
        
        for method in methods:
            try:
                content = await method(url)
                if content and len(content) > 10000:
                    self.logger.info(f"‚úÖ Got real content via {method.__name__}")
                    return content
            except Exception as e:
                self.logger.debug(f"{method.__name__} failed: {e}")
                continue
        
        return None

    async def try_direct_request(self, url: str) -> Optional[str]:
        """–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å"""
        await asyncio.sleep(random.uniform(1, 3))
        async with self.session.get(url) as response:
            if response.status == 200:
                return await response.text()
        return None

    async def try_with_cookies(self, url: str) -> Optional[str]:
        """–ó–∞–ø—Ä–æ—Å —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–º –ø–æ–ª—É—á–µ–Ω–∏–µ–º cookies"""
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        await asyncio.sleep(random.uniform(1, 2))
        async with self.session.get(self.base_url) as response:
            if response.status == 200:
                # –¢–µ–ø–µ—Ä—å –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ –Ω—É–∂–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                await asyncio.sleep(random.uniform(1, 2))
                async with self.session.get(url) as response:
                    if response.status == 200:
                        return await response.text()
        return None

    async def try_mobile_version(self, url: str) -> Optional[str]:
        """–ú–æ–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        mobile_url = url.replace('www.daft.ie', 'm.daft.ie')
        await asyncio.sleep(random.uniform(1, 2))
        async with self.session.get(mobile_url) as response:
            if response.status == 200:
                return await response.text()
        return None

    async def try_cached_version(self, url: str) -> Optional[str]:
        """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è"""
        cached_url = f"https://webcache.googleusercontent.com/search?q=cache:{url}"
        await asyncio.sleep(random.uniform(1, 2))
        async with self.session.get(cached_url) as response:
            if response.status == 200:
                return await response.text()
        return None

    def extract_real_properties(self, content: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        properties = []
        soup = BeautifulSoup(content, 'html.parser')
        
        # –ü–æ–∏—Å–∫ JSON –¥–∞–Ω–Ω—ã—Ö –≤ —Å–∫—Ä–∏–ø—Ç–∞—Ö (–æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö daft.ie)
        scripts = soup.find_all('script', type='application/json')
        for script in scripts:
            try:
                data = json.loads(script.string or "{}")
                if isinstance(data, dict) and 'props' in data:
                    # Daft.ie –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å props
                    props_data = data.get('props', {})
                    if 'pageProps' in props_data:
                        page_props = props_data['pageProps']
                        if 'listings' in page_props:
                            listings = page_props['listings']
                            for listing in listings:
                                prop = self.parse_real_listing(listing)
                                if prop:
                                    properties.append(prop)
            except json.JSONDecodeError:
                continue
        
        # –ü–æ–∏—Å–∫ –≤ –æ–±—ã—á–Ω—ã—Ö script —Ç–µ–≥–∞—Ö
        scripts = soup.find_all('script')
        for script in scripts:
            script_content = script.string or ""
            if 'window.__NEXT_DATA__' in script_content:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º JSON –∏–∑ Next.js –¥–∞–Ω–Ω—ã—Ö
                json_match = re.search(r'window\.__NEXT_DATA__\s*=\s*({.+?});', script_content)
                if json_match:
                    try:
                        next_data = json.loads(json_match.group(1))
                        listings = self.extract_listings_from_next_data(next_data)
                        for listing in listings:
                            prop = self.parse_real_listing(listing)
                            if prop:
                                properties.append(prop)
                    except json.JSONDecodeError:
                        continue
        
        # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –≤ HTML
        property_links = soup.find_all('a', href=True)
        for link in property_links:
            href = link.get('href', '')
            if '/for-rent/' in href and any(word in href for word in ['apartment', 'house', 'studio']):
                # –≠—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                full_url = href if href.startswith('http') else self.base_url + href
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏
                parent = link.find_parent()
                if parent:
                    title_elem = parent.find(['h1', 'h2', 'h3', 'h4'])
                    price_elem = parent.find(class_=re.compile(r'price', re.I))
                    
                    if title_elem:
                        title = title_elem.get_text(strip=True)
                        price = price_elem.get_text(strip=True) if price_elem else "See listing"
                        
                        if len(title) > 10 and 'cookie' not in title.lower():
                            properties.append({
                                'title': title,
                                'price': price,
                                'address': 'Dublin',
                                'url': full_url,
                                'bedrooms': None,
                                'bathrooms': None
                            })
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL
        unique_properties = []
        seen_urls = set()
        
        for prop in properties:
            url = prop.get('url', '')
            if url and url not in seen_urls and self.is_valid_real_property(prop):
                seen_urls.add(url)
                unique_properties.append(prop)
        
        return unique_properties

    def extract_listings_from_next_data(self, next_data: dict) -> List[dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ Next.js –¥–∞–Ω–Ω—ã—Ö"""
        listings = []
        
        def recursive_search(obj, key='listings'):
            """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
            if isinstance(obj, dict):
                if key in obj and isinstance(obj[key], list):
                    return obj[key]
                for value in obj.values():
                    result = recursive_search(value, key)
                    if result:
                        return result
            elif isinstance(obj, list):
                for item in obj:
                    result = recursive_search(item, key)
                    if result:
                        return result
            return None
        
        # –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        found_listings = recursive_search(next_data)
        if found_listings:
            listings.extend(found_listings)
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ–∏—Å–∫–∏
        for key in ['properties', 'results', 'items', 'data']:
            found = recursive_search(next_data, key)
            if found:
                listings.extend(found)
        
        return listings

    def parse_real_listing(self, listing: dict) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            title = listing.get('title') or listing.get('name') or listing.get('displayAddress')
            if not title or len(title) < 5:
                return None
            
            # –¶–µ–Ω–∞
            price_obj = listing.get('price') or listing.get('pricePerMonth') or listing.get('monthlyRent')
            if isinstance(price_obj, dict):
                price = f"‚Ç¨{price_obj.get('amount', 0):,}/month"
            else:
                price = str(price_obj) if price_obj else "See listing"
            
            # –ê–¥—Ä–µ—Å
            address = (listing.get('displayAddress') or 
                      listing.get('address') or 
                      listing.get('location') or 
                      'Dublin')
            
            # URL
            url = listing.get('seoUrl') or listing.get('url') or listing.get('link')
            if url and not url.startswith('http'):
                url = self.base_url + url
            
            # –°–ø–∞–ª—å–Ω–∏ –∏ –≤–∞–Ω–Ω—ã–µ
            bedrooms = listing.get('numBedrooms') or listing.get('bedrooms')
            bathrooms = listing.get('numBathrooms') or listing.get('bathrooms')
            
            return {
                'title': title,
                'price': price,
                'address': address,
                'url': url or self.base_url,
                'bedrooms': bedrooms,
                'bathrooms': bathrooms
            }
            
        except Exception as e:
            self.logger.debug(f"Failed to parse listing: {e}")
            return None

    def is_valid_real_property(self, prop: dict) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ"""
        title = prop.get('title', '')
        url = prop.get('url', '')
        
        # –ò—Å–∫–ª—é—á–∞–µ–º —Ñ–∞–ª—å—à–∏–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        invalid_keywords = [
            'demo', 'test', 'example', 'sample', 'fake',
            'generated', 'template', 'placeholder'
        ]
        
        title_lower = title.lower()
        url_lower = url.lower()
        
        for keyword in invalid_keywords:
            if keyword in title_lower or keyword in url_lower:
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ URL –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Å—ã–ª–∫–∞ daft.ie
        if '/for-rent/' not in url_lower:
            return False
            
        return len(title) > 10

    async def search_real_properties(self, city="Dublin", max_price=3000, min_bedrooms=2) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        self.logger.info(f"üîç Searching REAL properties: {city}, max ‚Ç¨{max_price}, {min_bedrooms}+ beds")
        
        if not self.session:
            await self.create_session()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_url = f"{self.base_url}/property-for-rent/{city.lower()}"
        
        search_params = []
        if max_price:
            search_params.append(f"rentalPrice_to={max_price}")
        if min_bedrooms:
            search_params.append(f"numBeds_from={min_bedrooms}")
        
        if search_params:
            search_url += "?" + "&".join(search_params)
        
        self.logger.info(f"Search URL: {search_url}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        content = await self.get_real_content(search_url)
        
        if not content:
            self.logger.error("‚ùå Failed to get any real content from daft.ie")
            return []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        properties = self.extract_real_properties(content)
        
        if not properties:
            self.logger.warning("‚ö†Ô∏è No real properties found in content")
            return []
        
        self.logger.info(f"‚úÖ Found {len(properties)} REAL properties")
        return properties

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()
            self.session = None

# –¢–µ—Å—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
async def test_real_parser():
    parser = RealDaftParser()
    
    try:
        print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –†–ï–ê–õ–¨–ù–´–ô –ø–∞—Ä—Å–µ—Ä daft.ie...")
        print("üö´ –ë–ï–ó —Ñ–∞–ª—å—à–∏–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ë–ï–ó –¥–µ–º–æ, –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è!")
        print("=" * 70)
        
        properties = await parser.search_real_properties("Dublin", 2500, 3)
        
        if properties:
            print(f"‚úÖ –£–°–ü–ï–•! –ù–∞–π–¥–µ–Ω–æ {len(properties)} –†–ï–ê–õ–¨–ù–´–• –æ–±—ä—è–≤–ª–µ–Ω–∏–π:")
            print()
            
            for i, prop in enumerate(properties[:5], 1):
                print(f"   {i}. üè† {prop['title']}")
                print(f"      üí∞ {prop['price']}")
                print(f"      üìç {prop['address']}")
                if prop.get('bedrooms'):
                    print(f"      üõèÔ∏è {prop['bedrooms']} —Å–ø–∞–ª–µ–Ω")
                print(f"      üîó {prop['url']}")
                print()
            
            return True, properties
        else:
            print("‚ùå –†–ï–ê–õ–¨–ù–´–ï –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            print("üîç –í–æ–∑–º–æ–∂–Ω–æ –Ω—É–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã –æ–±—Ö–æ–¥–∞")
            return False, []
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False, []
    finally:
        await parser.close()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    success, properties = asyncio.run(test_real_parser())
    
    if success:
        print(f"\nüéâ –†–ï–ê–õ–¨–ù–´–ô –ü–ê–†–°–ï–† –†–ê–ë–û–¢–ê–ï–¢! –ù–∞–π–¥–µ–Ω–æ {len(properties)} –Ω–∞—Å—Ç–æ—è—â–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π!")
    else:
        print("\n‚ö†Ô∏è –ù—É–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –º–µ—Ç–æ–¥—ã –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏.")
