#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å 3 —Å–ø–∞–ª—å–Ω—è–º–∏ –∑–∞ ‚Ç¨2500
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re

async def check_user_property():
    """–ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"""
    
    # URL –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    url = "http://www.daft.ie/for-rent/house-28-cabra-drive-dublin-7-north-circular-road-dublin-7/6193753"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä—è–≤–ª–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:")
    print(f"üîó {url}")
    print("="*80)
    
    async with aiohttp.ClientSession(headers=headers) as session:
        try:
            async with session.get(url) as response:
                print(f"üì° –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status}")
                
                if response.status == 200:
                    content = await response.text()
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title_elem = soup.find('title')
                    title = title_elem.get_text().strip() if title_elem else "No title"
                    print(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ø–∞–ª—å–Ω–∏ –Ω–∞—à–∏–º –º–µ—Ç–æ–¥–æ–º
                    bedrooms = extract_bedrooms_from_title(title)
                    print(f"üõèÔ∏è –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ —Å–ø–∞–ª–µ–Ω –Ω–∞—à–∏–º –ø–∞—Ä—Å–µ—Ä–æ–º: {bedrooms}")
                    
                    # –ò—â–µ–º —Ü–µ–Ω—É
                    price_elements = soup.find_all(string=lambda text: text and '‚Ç¨' in text and ('month' in text or 'per' in text))
                    if price_elements:
                        for price_text in price_elements[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –≤–∞—Ä–∏–∞–Ω—Ç–∞
                            print(f"üí∞ –ù–∞–π–¥–µ–Ω–Ω–∞—è —Ü–µ–Ω–∞: {price_text.strip()}")
                    
                    # –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ø–∞–ª—å–Ω—è—Ö –≤ —Ç–µ–∫—Å—Ç–µ
                    page_text = soup.get_text().lower()
                    
                    bedroom_indicators = [
                        'bedroom', 'double bedroom', 'single bedroom', 'twin bedroom',
                        'bed ', ' bed', 'beds'
                    ]
                    
                    print(f"\nüîç –ü–æ–∏—Å–∫ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π —Å–ø–∞–ª–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ:")
                    for indicator in bedroom_indicators:
                        if indicator in page_text:
                            # –ò—â–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥
                            import re
                            pattern = rf'.{{0,20}}{re.escape(indicator)}.{{0,20}}'
                            matches = re.findall(pattern, page_text)
                            if matches:
                                print(f"   ‚úÖ '{indicator}': {matches[0]}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞-–¥–∞–Ω–Ω—ã–µ
                    meta_desc = soup.find('meta', attrs={'name': 'description'})
                    if meta_desc:
                        print(f"\nüìã Meta description: {meta_desc.get('content')}")
                        meta_bedrooms = extract_bedrooms_from_title(meta_desc.get('content', ''))
                        print(f"üõèÔ∏è –°–ø–∞–ª—å–Ω–∏ –∏–∑ meta: {meta_bedrooms}")
                    
                elif response.status == 404:
                    print("‚ùå –û–±—ä—è–≤–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–æ (404)")
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞: {response.status}")
                    
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")

def extract_bedrooms_from_title(title: str) -> int:
    """–ù–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–ø–∞–ª–µ–Ω"""
    if not title:
        return 0
        
    title_lower = title.lower()
    
    print(f"   üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º: {title_lower}")
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è Studio
    if 'studio' in title_lower or 'bedsit' in title_lower:
        print("   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: Studio (0 —Å–ø–∞–ª–µ–Ω)")
        return 0
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ daft.ie (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)
    title_patterns = [
        (r'(\d+)\s+double\s+bedroom', "Double Bedroom"),
        (r'(\d+)\s+single\s+bedroom', "Single Bedroom"),
        (r'(\d+)\s+twin\s+bedroom', "Twin Bedroom"),
        (r'(\d+)\s+bedroom(?!s)', "Bedroom (singular)"),
        (r'(\d+)\s+bed\s+(?:apartment|house|flat|property)', "Bed + type"),
        (r'(\d+)-bed\s+(?:apartment|house|flat|property)', "X-bed + type"),
        (r'(\d+)-bedroom', "X-bedroom"),
    ]
    
    for pattern, description in title_patterns:
        matches = re.findall(pattern, title_lower)
        if matches:
            try:
                bedroom_count = int(matches[0])
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {description} = {bedroom_count}")
                # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã (–æ—Ç 0 –¥–æ 10 —Å–ø–∞–ª–µ–Ω)
                if 0 <= bedroom_count <= 10:
                    return bedroom_count
            except ValueError:
                continue
    
    print("   ‚ùå –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ")
    return 0

if __name__ == "__main__":
    asyncio.run(check_user_property())
