#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã daft.ie –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
"""
import asyncio
import aiohttp
import json
from bs4 import BeautifulSoup
import re

async def analyze_daft_structure():
    """–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã daft.ie"""
    print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã daft.ie...")
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        'Accept-Language': 'en-IE,en;q=0.9',
        'Referer': 'https://www.google.ie/'
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        url = "https://www.daft.ie/property-for-rent/dublin"
        
        try:
            async with session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    print(f"‚úÖ –ü–æ–ª—É—á–∏–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º script —Ç–µ–≥–∏
                    print("\nüìÑ –ê–Ω–∞–ª–∏–∑ script —Ç–µ–≥–æ–≤:")
                    scripts = soup.find_all('script')
                    for i, script in enumerate(scripts[:10]):  # –ü–µ—Ä–≤—ã–µ 10
                        script_content = script.string or ""
                        if len(script_content) > 100:
                            print(f"Script {i+1}: {len(script_content)} —Å–∏–º–≤–æ–ª–æ–≤")
                            
                            # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
                            if any(keyword in script_content.lower() for keyword in ['property', 'listing', 'rent', 'apartment']):
                                print(f"  ‚úÖ –°–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏")
                                
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞—á–∞–ª–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                                print(f"  –ù–∞—á–∞–ª–æ: {script_content[:200]}...")
                                
                                # –ò—â–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                                json_patterns = [
                                    r'window\.__NEXT_DATA__\s*=\s*({.+?});',
                                    r'window\.__INITIAL_STATE__\s*=\s*({.+?});',
                                    r'"listings":\s*\[',
                                    r'"properties":\s*\[',
                                    r'"results":\s*\['
                                ]
                                
                                for pattern in json_patterns:
                                    matches = re.findall(pattern, script_content)
                                    if matches:
                                        print(f"  üéØ –ù–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: {pattern}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Å—ã–ª–∫–∏
                    print("\nüîó –ê–Ω–∞–ª–∏–∑ —Å—Å—ã–ª–æ–∫:")
                    links = soup.find_all('a', href=True)
                    property_links = []
                    
                    for link in links:
                        href = link.get('href', '')
                        if '/for-rent/' in href and any(word in href for word in ['apartment', 'house', 'studio']):
                            full_url = href if href.startswith('http') else f"https://www.daft.ie{href}"
                            property_links.append(full_url)
                    
                    print(f"–ù–∞–π–¥–µ–Ω–æ {len(property_links)} —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è:")
                    for i, link in enumerate(property_links[:5]):
                        print(f"  {i+1}. {link}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º data-testid –∞—Ç—Ä–∏–±—É—Ç—ã
                    print("\nüè∑Ô∏è –ê–Ω–∞–ª–∏–∑ data-testid –∞—Ç—Ä–∏–±—É—Ç–æ–≤:")
                    testid_elements = soup.find_all(attrs={"data-testid": True})
                    for elem in testid_elements[:10]:
                        testid = elem.get('data-testid')
                        if 'property' in testid.lower() or 'listing' in testid.lower():
                            print(f"  ‚úÖ {testid}: {elem.name}")
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∞—Å—Å—ã
                    print("\nüé® –ê–Ω–∞–ª–∏–∑ CSS –∫–ª–∞—Å—Å–æ–≤:")
                    all_elements = soup.find_all(class_=True)
                    property_classes = set()
                    
                    for elem in all_elements:
                        classes = elem.get('class', [])
                        for cls in classes:
                            if any(keyword in cls.lower() for keyword in ['property', 'listing', 'card', 'item']):
                                property_classes.add(cls)
                    
                    print(f"–ù–∞–π–¥–µ–Ω–æ {len(property_classes)} –∫–ª–∞—Å—Å–æ–≤ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å—é:")
                    for cls in list(property_classes)[:10]:
                        print(f"  ‚Ä¢ {cls}")
                    
                    return True
                    
                else:
                    print(f"‚ùå –û—à–∏–±–∫–∞: {response.status}")
                    return False
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return False

if __name__ == "__main__":
    asyncio.run(analyze_daft_structure())
