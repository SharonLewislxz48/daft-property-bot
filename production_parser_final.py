#!/usr/bin/env python3
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥–∞–∫—à–Ω –ø–∞—Ä—Å–µ—Ä daft.ie —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
"""

import asyncio
import re
from typing import List, Dict, Any, Optional
from playwright.async_api import async_playwright
import json
import datetime

class AdvancedDaftParser:
    def __init__(self):
        self.base_url = "https://www.daft.ie"
        
    async def search_properties(self, search_url: str, limit: int = 15) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ —Å –±—Ä–∞—É–∑–µ—Ä–Ω–æ–π –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π"""
        print(f"üåê URL: {search_url}")
        
        async with async_playwright() as p:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
            browser = await p.chromium.launch(headless=True)
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            context = await browser.new_context(
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
                viewport={'width': 1920, 'height': 1080}
            )
            
            page = await context.new_page()
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                print("üìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞...")
                await page.goto(search_url, wait_until='networkidle', timeout=30000)
                await page.wait_for_timeout(3000)
                
                # –ü–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                total_count = await self._get_results_count(page)
                print(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {total_count}")
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
                property_urls = await self._collect_property_urls(page)
                print(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(property_urls)}")
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                urls_to_process = property_urls[:limit]
                print(f"üìù –ë—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å: {len(urls_to_process)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
                
                # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ
                results = []
                for i, url in enumerate(urls_to_process, 1):
                    print(f"  {i}/{len(urls_to_process)}: {self._get_property_name(url)}")
                    
                    property_data = await self._parse_property(page, url)
                    if property_data:
                        results.append(property_data)
                        self._print_property_summary(property_data)
                    else:
                        print("    ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
                
                return results
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
                return []
                
            finally:
                await browser.close()
    
    async def _get_results_count(self, page) -> int:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        try:
            h1_element = await page.wait_for_selector('h1', timeout=5000)
            h1_text = await h1_element.text_content()
            count_match = re.search(r'(\d+)', h1_text or '')
            return int(count_match.group(1)) if count_match else 0
        except:
            return 0
    
    async def _collect_property_urls(self, page) -> List[str]:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            property_links = await page.query_selector_all('a[href*="/for-rent/"]')
            
            unique_urls = set()
            for link in property_links:
                href = await link.get_attribute('href')
                if href and '/for-rent/' in href and href not in unique_urls:
                    if href.startswith('/'):
                        href = self.base_url + href
                    unique_urls.add(href)
            
            return list(unique_urls)
        except:
            return []
    
    def _get_property_name(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Ç–∞–µ–º–æ–µ –∏–º—è –∏–∑ URL"""
        try:
            parts = url.split('/')
            if len(parts) > 3:
                name = parts[-1].replace('-', ' ')
                return name[:40] + '...' if len(name) > 40 else name
        except:
            pass
        return url[-40:]
    
    async def _parse_property(self, page, url: str) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            await page.goto(url, wait_until='networkidle', timeout=15000)
            await page.wait_for_timeout(2000)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_content = await page.content()
            
            return {
                'url': url,
                'title': await self._extract_title(page),
                'price': await self._extract_price(page, page_content),
                'bedrooms': await self._extract_bedrooms(page, page_content),
                'property_type': self._extract_property_type(page_content),
                'location': await self._extract_location(page),
                'description': self._extract_description(page_content),
                'posted_date': self._extract_posted_date(page_content)
            }
            
        except Exception as e:
            print(f"    ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {url}: {e}")
            return None
    
    async def _extract_title(self, page) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            title_selectors = ['h1', '.TitleBlock_title', '[data-testid="title"]']
            
            for selector in title_selectors:
                element = await page.query_selector(selector)
                if element:
                    title = await element.text_content()
                    return title.strip() if title else None
        except:
            pass
        return None
    
    async def _extract_price(self, page, page_content: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ü–µ–Ω—É –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        # –ü—Ä–æ–±—É–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
        price_selectors = [
            '[data-testid="price"]',
            '.TitleBlock_price',
            'span:has-text("‚Ç¨")',
            '.price'
        ]
        
        for selector in price_selectors:
            try:
                price_element = await page.query_selector(selector)
                if price_element:
                    price_text = await price_element.text_content()
                    price_match = re.search(r'‚Ç¨([\d,]+)', price_text or '')
                    if price_match:
                        return int(price_match.group(1).replace(',', ''))
            except:
                continue
        
        # –ò—â–µ–º –≤ JSON –¥–∞–Ω–Ω—ã—Ö
        try:
            json_match = re.search(r'"price":\s*(\d+)', page_content)
            if json_match:
                return int(json_match.group(1))
        except:
            pass
        
        return None
    
    async def _extract_bedrooms(self, page, page_content: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π"""
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤ JSON –¥–∞–Ω–Ω—ã—Ö
        try:
            # –ò—â–µ–º –≤ structured data
            json_match = re.search(r'"numBedrooms":\s*"([^"]*)"', page_content)
            if json_match:
                bedrooms_text = json_match.group(1)
                
                # –ï—Å–ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ
                if bedrooms_text.isdigit():
                    return int(bedrooms_text)
                
                # –ï—Å–ª–∏ —ç—Ç–æ –¥–∏–∞–ø–∞–∑–æ–Ω –∏–ª–∏ —Å–ø–∏—Å–æ–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä "1, 2 & 3 bed")
                bed_numbers = re.findall(r'(\d+)', bedrooms_text)
                if bed_numbers:
                    # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö
                    return max([int(x) for x in bed_numbers])
        except:
            pass
        
        # –ò—â–µ–º –≤ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞—Ö –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
        try:
            bed_selectors = [
                '[data-testid="bed-bath"]',
                '.property-details',
                '.TitleBlock_meta'
            ]
            
            for selector in bed_selectors:
                element = await page.query_selector(selector)
                if element:
                    text = await element.text_content()
                    bed_match = re.search(r'(\d+)\s*bed', text or '', re.IGNORECASE)
                    if bed_match:
                        return int(bed_match.group(1))
        except:
            pass
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å - –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        try:
            bed_match = re.search(r'(\d+)\s*bedroom', page_content, re.IGNORECASE)
            if bed_match:
                bedrooms = int(bed_match.group(1))
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å (–Ω–µ –±–æ–ª—å—à–µ 10 —Å–ø–∞–ª–µ–Ω)
                if 1 <= bedrooms <= 10:
                    return bedrooms
        except:
            pass
        
        return None
    
    async def _extract_location(self, page) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ"""
        try:
            title_element = await page.query_selector('h1')
            if title_element:
                title = await title_element.text_content()
                location_match = re.search(r'Dublin\s+\d+|Dublin\s+\w+', title or '')
                if location_match:
                    return location_match.group()
        except:
            pass
        return None
    
    def _extract_property_type(self, page_content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
        try:
            # –ò—â–µ–º –≤ JSON –¥–∞–Ω–Ω—ã—Ö
            type_match = re.search(r'"@type":\s*"([^"]*)"', page_content)
            if type_match:
                return type_match.group(1)
            
            # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ
            if 'apartment' in page_content.lower():
                return 'Apartment'
            elif 'house' in page_content.lower():
                return 'House'
            elif 'studio' in page_content.lower():
                return 'Studio'
        except:
            pass
        return 'Unknown'
    
    def _extract_description(self, page_content: str, max_length: int = 200) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            # –ò—â–µ–º –≤ JSON –¥–∞–Ω–Ω—ã—Ö
            desc_match = re.search(r'"description":\s*"([^"]*)"', page_content)
            if desc_match:
                desc = desc_match.group(1)
                if len(desc) > max_length:
                    desc = desc[:max_length] + '...'
                return desc
        except:
            pass
        return 'No description'
    
    def _extract_posted_date(self, page_content: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        try:
            # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
            date_patterns = [
                r'"datePublished":\s*"([^"]*)"',
                r'"date":\s*"([^"]*)"',
                r'(\d{1,2}/\d{1,2}/\d{4})',
                r'(\d{4}-\d{2}-\d{2})'
            ]
            
            for pattern in date_patterns:
                match = re.search(pattern, page_content)
                if match:
                    return match.group(1)
        except:
            pass
        return 'Unknown'
    
    def _print_property_summary(self, prop: Dict[str, Any]):
        """–í—ã–≤–æ–¥–∏—Ç –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä—è–≤–ª–µ–Ω–∏–∏"""
        title = prop.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:50]
        price = f"‚Ç¨{prop['price']}" if prop.get('price') else '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'
        beds = f"{prop['bedrooms']} —Å–ø–∞–ª–µ–Ω" if prop.get('bedrooms') else '–°–ø–∞–ª—å–Ω–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã'
        print(f"    ‚úÖ {title} - {price}, {beds}")
    
    def format_results(self, results: List[Dict[str, Any]], show_details: bool = True) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤—ã–≤–æ–¥–∞"""
        if not results:
            return "‚ùå –û–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
        
        output = [f"üè† –ù–ê–ô–î–ï–ù–û {len(results)} –û–ë–™–Ø–í–õ–ï–ù–ò–ô:\n"]
        
        for i, prop in enumerate(results, 1):
            price_str = f"‚Ç¨{prop['price']}" if prop['price'] else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
            bedrooms_str = f"{prop['bedrooms']} —Å–ø–∞–ª–µ–Ω" if prop['bedrooms'] else "–°–ø–∞–ª—å–Ω–∏ –Ω–µ —É–∫–∞–∑–∞–Ω—ã"
            type_str = prop.get('property_type', '–¢–∏–ø –Ω–µ —É–∫–∞–∑–∞–Ω')
            location_str = prop.get('location', '–õ–æ–∫–∞—Ü–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞')
            
            output.append(f"{i}. {prop['title']}")
            output.append(f"   üí∞ {price_str} | üõèÔ∏è {bedrooms_str} | üè† {type_str}")
            output.append(f"   üìç {location_str}")
            
            if show_details:
                output.append(f"   üîó {prop['url']}")
            
            output.append("")
        
        return "\n".join(output)
    
    def get_statistics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º"""
        if not results:
            return {}
        
        prices = [prop['price'] for prop in results if prop.get('price')]
        bedrooms = [prop['bedrooms'] for prop in results if prop.get('bedrooms')]
        
        stats = {
            'total_count': len(results),
            'with_price': len(prices),
            'with_bedrooms': len(bedrooms)
        }
        
        if prices:
            stats.update({
                'avg_price': sum(prices) / len(prices),
                'min_price': min(prices),
                'max_price': max(prices)
            })
        
        if bedrooms:
            stats.update({
                'avg_bedrooms': sum(bedrooms) / len(bedrooms),
                'min_bedrooms': min(bedrooms),
                'max_bedrooms': max(bedrooms)
            })
        
        return stats

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ ADVANCED DAFT.IE PARSER")
    print("=" * 50)
    
    parser = AdvancedDaftParser()
    
    # URL –¥–ª—è –ø–æ–∏—Å–∫–∞ 3+ —Å–ø–∞–ª–µ–Ω –¥–æ ‚Ç¨2500 –≤ –î—É–±–ª–∏–Ω–µ
    search_url = "https://www.daft.ie/property-for-rent/dublin?rentalPrice_to=2500&numBeds_from=3"
    
    print(f"üéØ –ü–û–ò–°–ö: 3+ —Å–ø–∞–ª–µ–Ω –¥–æ ‚Ç¨2500 –≤ –î—É–±–ª–∏–Ω–µ")
    print(f"üîó URL: {search_url}")
    print()
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    start_time = datetime.datetime.now()
    results = await parser.search_properties(search_url, limit=15)
    duration = (datetime.datetime.now() - start_time).total_seconds()
    
    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 50)
    print("üìã –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê")
    print("=" * 50)
    
    formatted_output = parser.format_results(results)
    print(formatted_output)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("=" * 50)
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(results)}")
    
    if results:
        stats = parser.get_statistics(results)
        if stats.get('avg_price'):
            print(f"üí∞ –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: ‚Ç¨{stats['avg_price']:.0f}")
        if stats.get('avg_bedrooms'):
            print(f"üõèÔ∏è  –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω: {stats['avg_bedrooms']:.1f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    filename = f'daft_advanced_search_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

if __name__ == "__main__":
    asyncio.run(main())
