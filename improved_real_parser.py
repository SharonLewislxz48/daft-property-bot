#!/usr/bin/env python3
"""
–£–õ–£–ß–®–ï–ù–ù–´–ô —Ä–µ–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä daft.ie
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¢–û–õ–¨–ö–û –Ω–∞—Å—Ç–æ—è—â–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
"""
import asyncio
import aiohttp
import json
import random
from typing import List, Dict, Optional
from bs4 import BeautifulSoup
import logging
import re
from datetime import datetime

logger = logging.getLogger(__name__)

class ImprovedRealParser:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self):
        self.base_url = "https://www.daft.ie"
        self.session = None
        self.logger = logging.getLogger(__name__)
        
    async def create_session(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()
            
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'en-IE,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://www.google.ie/',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        
        self.session = aiohttp.ClientSession(
            headers=headers,
            timeout=aiohttp.ClientTimeout(total=30)
        )
        return self.session

    async def get_real_listings_page(self, city="Dublin", max_price=3000, min_bedrooms=3) -> Optional[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏"""
        if not self.session:
            await self.create_session()
        
        # URL –¥–ª—è –ø–æ–∏—Å–∫–∞
        search_url = f"{self.base_url}/property-for-rent/{city.lower()}"
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        params = []
        if max_price:
            params.append(f"rentalPrice_to={max_price}")
        if min_bedrooms:
            params.append(f"numBeds_from={min_bedrooms}")
        
        if params:
            search_url += "?" + "&".join(params)
        
        self.logger.info(f"Fetching: {search_url}")
        
        # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–µ—Ç–æ–¥–æ–≤
        methods = [
            self.direct_request,
            self.request_with_delay,
            self.mobile_request
        ]
        
        for method in methods:
            try:
                content = await method(search_url)
                if content and len(content) > 100000:  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–æ–π
                    self.logger.info(f"‚úÖ Got content via {method.__name__}: {len(content)} chars")
                    return content
            except Exception as e:
                self.logger.debug(f"{method.__name__} failed: {e}")
                continue
        
        return None

    async def direct_request(self, url: str) -> Optional[str]:
        """–ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å"""
        async with self.session.get(url) as response:
            if response.status == 200:
                return await response.text()
        return None

    async def request_with_delay(self, url: str) -> Optional[str]:
        """–ó–∞–ø—Ä–æ—Å —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π"""
        await asyncio.sleep(random.uniform(2, 4))
        async with self.session.get(url) as response:
            if response.status == 200:
                return await response.text()
        return None

    async def mobile_request(self, url: str) -> Optional[str]:
        """–ú–æ–±–∏–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å"""
        mobile_url = url.replace('www.daft.ie', 'm.daft.ie')
        async with self.session.get(mobile_url) as response:
            if response.status == 200:
                return await response.text()
        return None

    def extract_real_property_links(self, content: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        soup = BeautifulSoup(content, 'html.parser')
        links = soup.find_all('a', href=True)
        
        property_links = []
        
        for link in links:
            href = link.get('href', '')
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            if '/for-rent/' in href and any(word in href for word in ['apartment', 'house', 'studio']):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ–ª–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ (—Å–æ–¥–µ—Ä–∂–∏—Ç ID –≤ –∫–æ–Ω—Ü–µ)
                if re.search(r'/\d+$', href):  # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ —á–∏—Å–ª–æ (ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è)
                    full_url = href if href.startswith('http') else self.base_url + href
                    property_links.append(full_url)
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_links = list(set(property_links))
        self.logger.info(f"Found {len(unique_links)} unique property links")
        
        return unique_links

    async def get_property_details(self, property_url: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            await asyncio.sleep(random.uniform(0.5, 1.5))  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            
            async with self.session.get(property_url) as response:
                if response.status == 200:
                    content = await response.text()
                    return self.parse_property_page(content, property_url)
                
        except Exception as e:
            self.logger.debug(f"Failed to get details for {property_url}: {e}")
        
        return None

    def parse_property_page(self, content: str, url: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è"""
        try:
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title_selectors = [
                'h1',
                '[data-testid*="title"]',
                '.title',
                'title'
            ]
            
            title = "Property in Dublin"
            for selector in title_selectors:
                elem = soup.select_one(selector)
                if elem:
                    title_text = elem.get_text(strip=True)
                    if len(title_text) > 10 and 'daft' not in title_text.lower():
                        title = title_text
                        break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
            price_selectors = [
                '[data-testid*="price"]',
                '.price',
                '[class*="price" i]',
                '[id*="price" i]'
            ]
            
            price = "See listing"
            for selector in price_selectors:
                elem = soup.select_one(selector)
                if elem and '‚Ç¨' in elem.get_text():
                    price = elem.get_text(strip=True)
                    break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–¥—Ä–µ—Å
            address_selectors = [
                '[data-testid*="address"]',
                '.address',
                '[class*="address" i]',
                '[class*="location" i]'
            ]
            
            address = "Dublin"
            for selector in address_selectors:
                elem = soup.select_one(selector)
                if elem:
                    addr_text = elem.get_text(strip=True)
                    if len(addr_text) > 5:
                        address = addr_text
                        break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω
            bedrooms = None
            bedroom_patterns = [
                r'(\d+)\s*bed',
                r'(\d+)\s*bedroom',
                r'bed.*?(\d+)',
                r'bedroom.*?(\d+)'
            ]
            
            page_text = soup.get_text().lower()
            for pattern in bedroom_patterns:
                match = re.search(pattern, page_text)
                if match:
                    bedrooms = int(match.group(1))
                    break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–Ω–Ω—ã—Ö
            bathrooms = None
            bathroom_patterns = [
                r'(\d+)\s*bath',
                r'(\d+)\s*bathroom',
                r'bath.*?(\d+)',
                r'bathroom.*?(\d+)'
            ]
            
            for pattern in bathroom_patterns:
                match = re.search(pattern, page_text)
                if match:
                    bathrooms = int(match.group(1))
                    break
            
            return {
                'title': title,
                'price': price,
                'address': address,
                'url': url,
                'bedrooms': bedrooms,
                'bathrooms': bathrooms
            }
            
        except Exception as e:
            self.logger.debug(f"Failed to parse property page: {e}")
            return None

    def extract_quick_info_from_links(self, content: str, property_links: List[str]) -> List[Dict]:
        """–ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        properties = []
        soup = BeautifulSoup(content, 'html.parser')
        
        for link_url in property_links:
            # –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            link_element = soup.find('a', href=lambda x: x and link_url.endswith(x))
            
            if link_element:
                # –ò—â–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                container = link_element.find_parent(['div', 'article', 'section'])
                
                if container:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
                    title_elem = container.find(['h1', 'h2', 'h3', 'h4'])
                    price_elem = container.find(text=re.compile(r'‚Ç¨\d+'))
                    
                    if title_elem:
                        title = title_elem.get_text(strip=True)
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
                        price = "See listing"
                        if price_elem:
                            price = price_elem.strip()
                        else:
                            # –ò—â–µ–º —Ü–µ–Ω—É –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
                            container_text = container.get_text()
                            price_match = re.search(r'‚Ç¨[\d,]+', container_text)
                            if price_match:
                                price = price_match.group()
                        
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω
                        bedrooms = None
                        container_text = container.get_text().lower()
                        bed_match = re.search(r'(\d+)\s*bed', container_text)
                        if bed_match:
                            bedrooms = int(bed_match.group(1))
                        
                        properties.append({
                            'title': title,
                            'price': price,
                            'address': 'Dublin',
                            'url': link_url,
                            'bedrooms': bedrooms,
                            'bathrooms': None
                        })
        
        return properties

    async def search_real_properties(self, city="Dublin", max_price=3000, min_bedrooms=3) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π"""
        self.logger.info(f"üîç Searching REAL properties: {city}, max ‚Ç¨{max_price}, {min_bedrooms}+ beds")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏
        content = await self.get_real_listings_page(city, max_price, min_bedrooms)
        
        if not content:
            self.logger.error("‚ùå Failed to get listings page")
            return []
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        property_links = self.extract_real_property_links(content)
        
        if not property_links:
            self.logger.warning("‚ö†Ô∏è No property links found")
            return []
        
        self.logger.info(f"Found {len(property_links)} property links")
        
        # –ë—ã—Å—Ç—Ä–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Å–ø–∏—Å–∫–∞
        properties = self.extract_quick_info_from_links(content, property_links)
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–µ—Ç–∞–ª–µ–π, –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
        if len(properties) < 5:
            self.logger.info("Getting detailed info from individual pages...")
            
            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 —Å—Å—ã–ª–æ–∫ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            for url in property_links[:10]:
                prop_details = await self.get_property_details(url)
                if prop_details:
                    properties.append(prop_details)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ø–∞–ª–µ–Ω
        if min_bedrooms:
            filtered_properties = []
            for prop in properties:
                if prop.get('bedrooms') and prop['bedrooms'] >= min_bedrooms:
                    filtered_properties.append(prop)
                elif not prop.get('bedrooms'):  # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ, –≤–∫–ª—é—á–∞–µ–º
                    filtered_properties.append(prop)
            properties = filtered_properties
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_properties = []
        seen_urls = set()
        
        for prop in properties:
            url = prop.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_properties.append(prop)
        
        self.logger.info(f"‚úÖ Found {len(unique_properties)} unique REAL properties")
        return unique_properties

    async def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–µ—Å—Å–∏–∏"""
        if self.session:
            await self.session.close()
            self.session = None

# –¢–µ—Å—Ç —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞
async def test_improved_parser():
    parser = ImprovedRealParser()
    
    try:
        print("üéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –£–õ–£–ß–®–ï–ù–ù–´–ô —Ä–µ–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä...")
        print("‚úÖ –ò–∑–≤–ª–µ–∫–∞–µ–º –¢–û–õ–¨–ö–û –Ω–∞—Å—Ç–æ—è—â–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏")
        print("=" * 70)
        
        properties = await parser.search_real_properties("Dublin", 2500, 3)
        
        if properties:
            print(f"üéâ –£–°–ü–ï–•! –ù–∞–π–¥–µ–Ω–æ {len(properties)} –†–ï–ê–õ–¨–ù–´–• –æ–±—ä—è–≤–ª–µ–Ω–∏–π:")
            print()
            
            for i, prop in enumerate(properties[:8], 1):
                print(f"   {i}. üè† {prop['title']}")
                print(f"      üí∞ {prop['price']}")
                print(f"      üìç {prop['address']}")
                if prop.get('bedrooms'):
                    print(f"      üõèÔ∏è {prop['bedrooms']} —Å–ø–∞–ª–µ–Ω")
                print(f"      üîó {prop['url']}")
                print()
            
            return True, properties
        else:
            print("‚ùå –†–ï–ê–õ–¨–ù–´–ï –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return False, []
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False, []
    finally:
        await parser.close()

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    success, properties = asyncio.run(test_improved_parser())
    
    if success:
        print(f"\nüéâ –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–ê–†–°–ï–† –†–ê–ë–û–¢–ê–ï–¢! –ù–∞–π–¥–µ–Ω–æ {len(properties)} –Ω–∞—Å—Ç–æ—è—â–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π!")
        print("üîó –í—Å–µ —Å—Å—ã–ª–∫–∏ –≤–µ–¥—É—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã daft.ie!")
    else:
        print("\n‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞.")
