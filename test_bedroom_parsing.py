#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ø–∞–ª–µ–Ω –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup
import re

async def test_bedroom_parsing():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ø–∞–ª–µ–Ω –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    test_urls = [
        "https://www.daft.ie/for-rent/apartment-1-bedroom-apartment-marshall-yards-east-road-dublin-3/6141962",
        "https://www.daft.ie/for-rent/apartment-2-bed-apartment-eglinton-place-eglinton-road-dublin-4/5811438",
        "https://www.daft.ie/for-rent/apartment-2-bedroom-apartment-occu-hayfield-churchview-road-killiney-co-dublin/5900743"
    ]
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        for url in test_urls:
            print(f"\n{'='*60}")
            print(f"üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º: {url}")
            
            try:
                async with session.get(url) as response:
                    if response.status == 200:
                        content = await response.text()
                        soup = BeautifulSoup(content, 'html.parser')
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                        title_elem = soup.find('title')
                        title = title_elem.get_text().strip() if title_elem else "No title"
                        print(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
                        
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                        analyze_bedroom_content(title, soup)
                        
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞: {response.status}")
                        
            except Exception as e:
                print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")

def analyze_bedroom_content(title: str, soup: BeautifulSoup):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∞–ª–µ–Ω"""
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    page_text = soup.get_text()
    
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞:")
    extract_bedrooms_from_title(title)
    
    print(f"\nüîç –ü–æ–∏—Å–∫ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
    search_bedroom_patterns(page_text)
    
    print(f"\nüîç –ü–æ–∏—Å–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    search_structured_data(soup)

def extract_bedrooms_from_title(title: str) -> int:
    """–ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∞–ª–µ–Ω –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    
    title_lower = title.lower()
    print(f"   –ó–∞–≥–æ–ª–æ–≤–æ–∫ (lower): {title_lower}")
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ daft.ie
    title_patterns = [
        (r'(\d+)\s+double\s+bedroom', "Double Bedroom"),
        (r'(\d+)\s+single\s+bedroom', "Single Bedroom"),
        (r'(\d+)\s+twin\s+bedroom', "Twin Bedroom"),
        (r'(\d+)\s+bedroom(?!s)', "Bedroom (singular)"),
        (r'(\d+)\s+bed\s+(?:apartment|house|flat)', "Bed + type"),
        (r'(\d+)-bed\s+(?:apartment|house|flat)', "X-bed + type"),
        (r'(\d+)-bedroom', "X-bedroom"),
        (r'studio', "Studio (0 beds)"),
    ]
    
    for pattern, description in title_patterns:
        if pattern == r'studio':
            if 'studio' in title_lower:
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {description}")
                return 0
        else:
            matches = re.findall(pattern, title_lower)
            if matches:
                bedroom_count = int(matches[0])
                print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {description} = {bedroom_count}")
                return bedroom_count
    
    print(f"   ‚ùå –ü–∞—Ç—Ç–µ—Ä–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ")
    return -1

def search_bedroom_patterns(page_text: str):
    """–ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–ø–∞–ª–µ–Ω –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    
    text_lower = page_text.lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
    bedroom_phrases = [
        "double bedroom",
        "single bedroom", 
        "twin bedroom",
        "master bedroom",
        "en-suite bedroom",
        "bedroom with",
        "large bedroom",
        "spacious bedroom"
    ]
    
    print(f"   –ò—â–µ–º —Ñ—Ä–∞–∑—ã —Å–æ —Å–ø–∞–ª—å–Ω—è–º–∏:")
    for phrase in bedroom_phrases:
        count = text_lower.count(phrase)
        if count > 0:
            print(f"   ‚úÖ '{phrase}' –Ω–∞–π–¥–µ–Ω–æ {count} —Ä–∞–∑")
    
    # –ò—â–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    numeric_patterns = [
        (r'(\d+)\s+double\s+bedroom', "X double bedroom"),
        (r'(\d+)\s+single\s+bedroom', "X single bedroom"),
        (r'(\d+)\s+bedroom', "X bedroom"),
        (r'(\d+)\s+bed\b', "X bed"),
    ]
    
    print(f"\n   –ò—â–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:")
    for pattern, description in numeric_patterns:
        matches = re.findall(pattern, text_lower)
        if matches:
            for match in matches:
                print(f"   ‚úÖ {description}: {match}")

def search_structured_data(soup: BeautifulSoup):
    """–ò—â–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Å–ø–∞–ª—å–Ω—è—Ö"""
    
    # –ò—â–µ–º –≤ –º–µ—Ç–∞—Ç–µ–≥–∞—Ö
    meta_tags = soup.find_all('meta')
    for meta in meta_tags:
        if meta.get('property') or meta.get('name'):
            content = meta.get('content', '')
            if 'bedroom' in content.lower():
                print(f"   üìã Meta: {meta.get('property') or meta.get('name')} = {content}")
    
    # –ò—â–µ–º –≤ JSON-LD –¥–∞–Ω–Ω—ã—Ö
    scripts = soup.find_all('script', type='application/ld+json')
    for script in scripts:
        if script.string and 'bedroom' in script.string.lower():
            print(f"   üìã JSON-LD —Å–æ–¥–µ—Ä–∂–∏—Ç 'bedroom'")
    
    # –ò—â–µ–º –≤ –∫–ª–∞—Å—Å–∞—Ö –∏ ID
    bedroom_elements = soup.find_all(lambda tag: tag.get('class') and 
                                   any('bedroom' in str(cls).lower() for cls in tag.get('class')))
    if bedroom_elements:
        print(f"   üìã –ù–∞–π–¥–µ–Ω–æ {len(bedroom_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–ª–∞—Å—Å–æ–º 'bedroom'")
    
    # –ò—â–µ–º –≤ data –∞—Ç—Ä–∏–±—É—Ç–∞—Ö
    data_elements = soup.find_all(lambda tag: any(attr.startswith('data-') and 'bedroom' in attr.lower() 
                                                for attr in tag.attrs.keys()))
    if data_elements:
        print(f"   üìã –ù–∞–π–¥–µ–Ω–æ {len(data_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å data-bedroom –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏")

if __name__ == "__main__":
    asyncio.run(test_bedroom_parsing())
