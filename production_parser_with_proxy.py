#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
"""

import asyncio
import aiohttp
import re
import json
import logging
import random
from typing import List, Dict, Optional

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DaftParserWithProxy:
    def __init__(self):
        self.base_url = "https://www.daft.ie"
        self.session = None
        self.free_proxies = [
            # –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ HTTP –ø—Ä–æ–∫—Å–∏ (–æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            "http://proxy-list.download/api/v1/get?type=http",
            "http://free-proxy-list.net/",
            "http://www.proxy-list.download/HTTP",
        ]
        
        # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.test_proxies = [
            "http://103.149.162.194:80",
            "http://185.162.235.164:80", 
            "http://103.145.45.10:55443",
            "http://103.156.17.71:8080",
            "http://139.255.25.106:8080",
        ]

    async def get_free_proxies(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏"""
        proxies = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–æ–∫—Å–∏
        proxies.extend(self.test_proxies)
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å–≤–µ–∂–∏–µ –ø—Ä–æ–∫—Å–∏ –∏–∑ API
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    "https://api.proxyscrape.com/v2/?request=get&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all",
                    timeout=10
                ) as response:
                    if response.status == 200:
                        proxy_text = await response.text()
                        for line in proxy_text.strip().split('\n'):
                            if ':' in line:
                                proxies.append(f"http://{line.strip()}")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–≤–µ–∂–∏–µ –ø—Ä–æ–∫—Å–∏: {e}")
        
        return proxies[:20]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20 –ø—Ä–æ–∫—Å–∏

    async def test_proxy(self, proxy_url: str) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –ø—Ä–æ–∫—Å–∏"""
        try:
            connector = aiohttp.TCPConnector(ssl=False)
            timeout = aiohttp.ClientTimeout(total=10)
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout
            ) as session:
                async with session.get(
                    "https://httpbin.org/ip",
                    proxy=proxy_url,
                    headers=self._get_headers()
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        logger.info(f"–ü—Ä–æ–∫—Å–∏ {proxy_url} —Ä–∞–±–æ—Ç–∞–µ—Ç. IP: {result.get('origin')}")
                        return True
        except Exception as e:
            logger.debug(f"–ü—Ä–æ–∫—Å–∏ {proxy_url} –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
        
        return False

    async def test_daft_access(self, proxy_url: Optional[str] = None) -> bool:
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø –∫ daft.ie —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏"""
        try:
            connector = aiohttp.TCPConnector(ssl=False)
            timeout = aiohttp.ClientTimeout(total=15)
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout
            ) as session:
                kwargs = {
                    "headers": self._get_headers(),
                    "allow_redirects": True
                }
                
                if proxy_url:
                    kwargs["proxy"] = proxy_url
                
                async with session.get(f"{self.base_url}/", **kwargs) as response:
                    logger.info(f"–¢–µ—Å—Ç daft.ie {'—Å –ø—Ä–æ–∫—Å–∏ ' + proxy_url if proxy_url else '–±–µ–∑ –ø—Ä–æ–∫—Å–∏'}: {response.status}")
                    return response.status == 200
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ daft.ie: {e}")
        
        return False

    def _get_headers(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏"""
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0",
        ]
        
        return {
            "User-Agent": random.choice(user_agents),
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.5",
            "Accept-Encoding": "gzip, deflate",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0",
        }

    async def search_properties(self, bedrooms: int = 2, max_price: int = 2500, location: str = "dublin-city") -> List[Dict]:
        """–ü–æ–∏—Å–∫ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏
        logger.info("–ü—Ä–æ–±—É–µ–º –¥–æ—Å—Ç—É–ø –∫ daft.ie –±–µ–∑ –ø—Ä–æ–∫—Å–∏...")
        if await self.test_daft_access():
            logger.info("‚úÖ –î–æ—Å—Ç—É–ø –±–µ–∑ –ø—Ä–æ–∫—Å–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç!")
            return await self._search_with_proxy(None, bedrooms, max_price, location)
        
        # –ï—Å–ª–∏ –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ–∫—Å–∏
        logger.info("‚ùå –ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω. –ò—â–µ–º —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ–∫—Å–∏...")
        
        proxies = await self.get_free_proxies()
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        for i, proxy in enumerate(proxies, 1):
            logger.info(f"–¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏ {i}/{len(proxies)}: {proxy}")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏
            if not await self.test_proxy(proxy):
                continue
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –¥–æ—Å—Ç—É–ø –∫ daft.ie —á–µ—Ä–µ–∑ —ç—Ç–æ—Ç –ø—Ä–æ–∫—Å–∏
            if await self.test_daft_access(proxy):
                logger.info(f"‚úÖ –†–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏ –Ω–∞–π–¥–µ–Ω: {proxy}")
                return await self._search_with_proxy(proxy, bedrooms, max_price, location)
        
        logger.error("‚ùå –ù–∏ –æ–¥–∏–Ω –ø—Ä–æ–∫—Å–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç")
        return []

    async def _search_with_proxy(self, proxy_url: Optional[str], bedrooms: int, max_price: int, location: str) -> List[Dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–æ–∫—Å–∏ (–∏–ª–∏ –±–µ–∑ –Ω–µ–≥–æ)"""
        search_url = f"{self.base_url}/property-for-rent/{location}?numBeds={bedrooms}&maxPrice={max_price}"
        
        try:
            connector = aiohttp.TCPConnector(ssl=False)
            timeout = aiohttp.ClientTimeout(total=30)
            
            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout
            ) as session:
                kwargs = {
                    "headers": self._get_headers(),
                    "allow_redirects": True
                }
                
                if proxy_url:
                    kwargs["proxy"] = proxy_url
                
                logger.info(f"–ó–∞–ø—Ä–æ—Å –∫: {search_url}")
                async with session.get(search_url, **kwargs) as response:
                    if response.status != 200:
                        logger.error(f"–û—à–∏–±–∫–∞ HTTP: {response.status}")
                        return []
                    
                    html = await response.text()
                    return self._extract_properties_from_html(html)
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}")
            return []

    def _extract_properties_from_html(self, html: str) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ HTML"""
        properties = []
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –¥–∞–Ω–Ω—ã–µ –≤ —Å–∫—Ä–∏–ø—Ç–µ
            json_match = re.search(r'<script[^>]*id="__NEXT_DATA__"[^>]*>(.*?)</script>', html, re.DOTALL)
            if json_match:
                json_data = json.loads(json_match.group(1))
                properties = self._extract_from_json(json_data)
                
            if properties:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(properties)} –æ–±—ä–µ–∫—Ç–æ–≤ —á–µ—Ä–µ–∑ JSON")
                return properties
            
            # –ï—Å–ª–∏ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å HTML
            logger.info("JSON –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º HTML –ø–∞—Ä—Å–∏–Ω–≥...")
            properties = self._extract_from_html_regex(html)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return properties

    def _extract_from_json(self, json_data: dict) -> List[Dict]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
        properties = []
        
        try:
            # –ò—â–µ–º –¥–∞–Ω–Ω—ã–µ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –≤ JSON
            props_data = json_data.get('props', {}).get('pageProps', {})
            
            # –†–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
            listings = (
                props_data.get('listings', []) or
                props_data.get('searchResults', {}).get('listings', []) or
                props_data.get('properties', [])
            )
            
            for item in listings:
                prop = {
                    'title': item.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'),
                    'price': item.get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞'),
                    'location': item.get('location', '–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'bedrooms': item.get('bedrooms', '–ù–µ —É–∫–∞–∑–∞–Ω–æ'),
                    'url': f"https://www.daft.ie{item.get('seoPath', '')}" if item.get('seoPath') else None
                }
                properties.append(prop)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        
        return properties

    def _extract_from_html_regex(self, html: str) -> List[Dict]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è"""
        properties = []
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å HTML –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–∫ fallback
        logger.info("HTML –ø–∞—Ä—Å–∏–Ω–≥ –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
        
        return properties

async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ —Å –ø—Ä–æ–∫—Å–∏"""
    parser = DaftParserWithProxy()
    
    print("üîç –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–∫—Å–∏...")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
    properties = await parser.search_properties(
        bedrooms=2,
        max_price=2500,
        location="dublin-city"
    )
    
    if properties:
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(properties)} –æ–±—ä–µ–∫—Ç–æ–≤:")
        for i, prop in enumerate(properties[:5], 1):
            print(f"\n{i}. {prop['title']}")
            print(f"   –¶–µ–Ω–∞: {prop['price']}")
            print(f"   –ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: {prop['location']}")
            print(f"   –°–ø–∞–ª—å–Ω–∏: {prop['bedrooms']}")
            if prop['url']:
                print(f"   URL: {prop['url']}")
    else:
        print("‚ùå –û–±—ä–µ–∫—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

if __name__ == "__main__":
    asyncio.run(main())
