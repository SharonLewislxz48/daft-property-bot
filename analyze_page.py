#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã Daft.ie
"""
import asyncio
import aiohttp
import random
from bs4 import BeautifulSoup

async def analyze_daft_page():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã Daft.ie"""
    
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1'
    }
    
    url = "https://www.daft.ie/property-for-rent/dublin?rentalPrice_to=3000&numBeds_from=2"
    
    print("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã Daft.ie...")
    print("=" * 50)
    
    async with aiohttp.ClientSession(headers=headers) as session:
        await asyncio.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞
        
        async with session.get(url) as response:
            print(f"üìä Status: {response.status}")
            print(f"üìè Content-Length: {response.headers.get('Content-Length', 'Unknown')}")
            
            html = await response.text()
            print(f"üìÑ HTML Length: {len(html)} characters")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            soup = BeautifulSoup(html, 'html.parser')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ JavaScript-–∫–æ–Ω—Ç–µ–Ω—Ç–∞
            scripts = soup.find_all('script')
            print(f"üìú JavaScript blocks: {len(scripts)}")
            
            # –ò—â–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ React/SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            react_indicators = [
                'react', 'ReactDOM', '__NEXT_DATA__', 'window.__APP_STATE__',
                'application/json', 'hydrate', 'clientside'
            ]
            
            for indicator in react_indicators:
                if indicator in html:
                    print(f"üîß Found SPA indicator: {indicator}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            title = soup.find('title')
            if title:
                print(f"üì∞ Page title: {title.get_text()}")
            
            # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
            content_selectors = [
                'main', '[role="main"]', '#main', '.main-content',
                '[data-testid]', '[class*="result" i]', '[class*="listing" i]'
            ]
            
            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    print(f"üì¶ Found {len(elements)} elements with selector: {selector}")
                    if len(elements) < 10:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ–º–Ω–æ–≥–æ
                        for elem in elements[:3]:
                            classes = elem.get('class', [])
                            test_id = elem.get('data-testid', '')
                            print(f"   - Classes: {classes}, TestID: {test_id}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –∏–ª–∏ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
            error_indicators = [
                'blocked', 'forbidden', 'access denied', 'cloudflare',
                'bot protection', 'security check', 'captcha'
            ]
            
            html_lower = html.lower()
            for indicator in error_indicators:
                if indicator in html_lower:
                    print(f"üö´ Found blocking indicator: {indicator}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç—å HTML –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            print("\nüìù Sample HTML structure:")
            print("-" * 30)
            
            # –ò—â–µ–º JSON –¥–∞–Ω–Ω—ã–µ
            script_tags = soup.find_all('script', type='application/json')
            if script_tags:
                print(f"üîç Found {len(script_tags)} JSON script tags")
                for i, tag in enumerate(script_tags[:2]):
                    content = tag.string or tag.get_text()
                    if content and len(content) > 100:
                        print(f"   JSON {i+1}: {content[:200]}...")
            
            # –ò—â–µ–º __NEXT_DATA__ (Next.js)
            next_data_script = soup.find('script', string=lambda text: text and '__NEXT_DATA__' in text)
            if next_data_script:
                print("üéØ Found __NEXT_DATA__ - —ç—Ç–æ Next.js –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")
                content = next_data_script.string
                if 'properties' in content or 'listings' in content:
                    print("‚úÖ JSON —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ–± –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö!")

if __name__ == "__main__":
    asyncio.run(analyze_daft_page())
